# ğŸ¯ Unified Digits & Shapes Recognition System

Há»‡ thá»‘ng nháº­n diá»‡n chá»¯ sá»‘ viáº¿t tay vÃ  hÃ¬nh há»c trong áº£nh sá»­ dá»¥ng Deep Learning vá»›i kiáº¿n trÃºc Detection + Classification.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“– MÃ´ táº£

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng hoÃ n chá»‰nh Ä‘á»ƒ nháº­n diá»‡n vÃ  phÃ¢n loáº¡i:
- **10 chá»¯ sá»‘**: 0-9 (tá»« MNIST dataset)
- **9 hÃ¬nh há»c**: Circle, Triangle, Square, Pentagon, Hexagon, Heptagon, Octagon, Nonagon, Star

### Pipeline

```
Input Image â†’ Detection (Traditional CV/CRAFT) â†’ Classification (EfficientNet-B0) â†’ Output (Annotated Image + JSON)
```

### Äáº·c Ä‘iá»ƒm ná»•i báº­t

- âœ… **19 classes**: Digits (0-9) + Shapes (9 loáº¡i)
- âœ… **Äá»™ chÃ­nh xÃ¡c cao**: ~99% validation accuracy
- âœ… **Inference nhanh**: ~100-300ms/áº£nh
- âœ… **Linh hoáº¡t**: Há»— trá»£ nhiá»u phÆ°Æ¡ng phÃ¡p detection
- âœ… **Dá»… sá»­ dá»¥ng**: API Ä‘Æ¡n giáº£n vÃ  rÃµ rÃ ng

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng

- Python 3.8+
- CUDA 11.8+ (optional, cho GPU acceleration)
- RAM: 8GB+ (16GB recommended)
- Disk space: ~5GB (cho datasets vÃ  models)

### BÆ°á»›c 1: Clone repository

```bash
# Clone project tá»« GitHub
git clone https://github.com/your-username/BTL_XLA.git
cd BTL_XLA
```

### BÆ°á»›c 2: Setup Conda Environment (Khuyáº¿n nghá»‹)

```bash
# Táº¡o conda environment má»›i
conda create -n btl_xla python=3.10 -y

# Activate environment
conda activate btl_xla

# CÃ i Ä‘áº·t PyTorch vá»›i CUDA (náº¿u cÃ³ GPU)
conda install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia -y

# CÃ i Ä‘áº·t cÃ¡c dependencies cÃ²n láº¡i
pip install -r requirements.txt
```

**Hoáº·c náº¿u chá»‰ dÃ¹ng CPU:**

```bash
conda create -n btl_xla python=3.10 -y
conda activate btl_xla
conda install pytorch torchvision cpuonly -c pytorch -y
pip install -r requirements.txt
```

### BÆ°á»›c 3: Táº£i vÃ  chuáº©n bá»‹ dá»¯ liá»‡u

#### 3.1. MNIST Dataset

```bash
# Giáº£i nÃ©n mnist_competition.zip (náº¿u cÃ³)
unzip mnist_competition.zip

# Hoáº·c táº£i tá»« Kaggle/Google Drive
# Cáº¥u trÃºc: mnist_competition/train/ vÃ  mnist_competition/train_label.csv
```

#### 3.2. Shapes Dataset

```bash
# Giáº£i nÃ©n dataset trong Shapes_Classifier
cd Shapes_Classifier
unzip dataset.zip
cd ..
```

#### 3.3. CRAFT Weights (cho Hybrid Detector)

```bash
# Táº¡o thÆ° má»¥c weights
mkdir weights

# Táº£i CRAFT weights
wget https://drive.google.com/uc?id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ -O weights/craft_mlt_25k.pth

# Hoáº·c dÃ¹ng gdown
pip install gdown
gdown https://drive.google.com/uc?id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ -O weights/craft_mlt_25k.pth
```

### Chuáº©n bá»‹ dá»¯ liá»‡u hoÃ n táº¥t

Äáº£m báº£o cáº¥u trÃºc thÆ° má»¥c nhÆ° sau:

```
BTL_XLA/
â”œâ”€â”€ mnist_competition/
â”‚   â”œâ”€â”€ train/              # 60,000 MNIST images
â”‚   â”œâ”€â”€ train_label.csv
â”‚   â””â”€â”€ public_test/
â”œâ”€â”€ Shapes_Classifier/
â”‚   â””â”€â”€ dataset/output/     # 90,000 shape images (Circle, Square, etc.)
â”œâ”€â”€ weights/
â”‚   â””â”€â”€ craft_mlt_25k.pth   # CRAFT pretrained weights (~85MB)
â”œâ”€â”€ unified_model_19classes_best.pth  # Trained classifier
â””â”€â”€ label_mapping.json
```

## ğŸ“š HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. Training Classifier

Train mÃ´ hÃ¬nh EfficientNet-B0 trÃªn 19 classes:

#### Sá»­ dá»¥ng Python Script

```bash
python train_unified_classifier.py --epochs 20 --batch-size 64
```

**Tham sá»‘:**
- `--epochs`: Sá»‘ epoch (máº·c Ä‘á»‹nh: 20)
- `--batch-size`: Batch size (máº·c Ä‘á»‹nh: 64)
- `--lr`: Learning rate (máº·c Ä‘á»‹nh: 1e-4)
- `--device`: 'cuda' hoáº·c 'cpu'

#### Sá»­ dá»¥ng Jupyter Notebook

```bash
jupyter notebook train_unified_classifier.ipynb
```

**Output:**
- `unified_model_19classes_best.pth`: Model Ä‘Ã£ train
- `label_mapping.json`: Ãnh xáº¡ class labels
- `training_history.png`: Biá»ƒu Ä‘á»“ loss/accuracy

### 2. Pipeline - Inference trÃªn áº£nh

#### 2.1. Xá»­ lÃ½ áº£nh cÃ³ sáºµn (táº¥t cáº£ classes)

```bash
python pipeline.py --image Sample.png --output Sample_result.png
```

#### 2.2. Chá»‰ nháº­n diá»‡n SHAPES

```bash
python pipeline.py --image Sample.png --target shapes --output Sample_shapes_only.png
```

#### 2.3. Chá»‰ nháº­n diá»‡n DIGITS

```bash
python pipeline.py --image Sample.png --target digits --output Sample_digits_only.png
```

#### 2.4. Sá»­ dá»¥ng Hybrid Detector (CRAFT + Traditional CV)

```bash
python pipeline.py --image Sample.png --detector hybrid --target all
```

#### 2.5. Táº¡o áº£nh test synthetic tá»± Ä‘á»™ng

```bash
# Táº¡o áº£nh vá»›i 5 objects (máº·c Ä‘á»‹nh)
python pipeline.py --generate

# Táº¡o áº£nh vá»›i 10 objects
python pipeline.py --generate --num-objects 10

# Táº¡o vÃ  chá»‰ detect shapes
python pipeline.py --generate --num-objects 8 --target shapes
```

**Pipeline Output:**
- `*_result.png`: áº¢nh Ä‘Æ°á»£c annotate vá»›i bounding boxes
- `*_result.json`: Káº¿t quáº£ detection á»Ÿ Ä‘á»‹nh dáº¡ng JSON

**Pipeline Arguments:**

| Argument | Choices | Default | MÃ´ táº£ |
|----------|---------|---------|-------|
| `--image` | path | None | ÄÆ°á»ng dáº«n áº£nh input |
| `--output` | path | Auto | ÄÆ°á»ng dáº«n áº£nh output |
| `--target` | `digits`, `shapes`, `all` | `all` | Loáº¡i objects cáº§n detect |
| `--detector` | `traditional`, `hybrid` | `traditional` | PhÆ°Æ¡ng phÃ¡p detection |
| `--generate` | flag | False | Táº¡o áº£nh test synthetic |
| `--num-objects` | int | 5 | Sá»‘ objects trong synthetic scene |
| `--model` | path | `unified_model_19classes_best.pth` | Model weights |
| `--labels` | path | `label_mapping.json` | Label mapping |
| `--device` | `cuda`, `cpu` | Auto | Device Ä‘á»ƒ inference |

### 3. Evaluation

ÄÃ¡nh giÃ¡ hiá»‡u nÄƒng model:

```bash
python evaluate_model.py
```

**Output:**
- Per-class accuracy report
- Confusion matrix
- Classification report
- `per_class_performance.csv`

### 4. Sá»­ dá»¥ng nhÆ° má»™t module

```python
from pipeline import UnifiedPipeline

# Khá»Ÿi táº¡o pipeline - Detect ALL
pipeline = UnifiedPipeline(
    model_path='unified_model_19classes_best.pth',
    label_mapping_path='label_mapping.json',
    device='cuda',  # hoáº·c 'cpu'
    detector_type='traditional',  # hoáº·c 'hybrid'
    target_classes='all'  # 'digits', 'shapes', hoáº·c 'all'
)

# Xá»­ lÃ½ áº£nh
results = pipeline.process_file('test_image.png')

# Káº¿t quáº£
print(f"Detected {len(results['labels'])} objects")
for label, conf in zip(results['labels'], results['confidences']):
    print(f"Class: {label}, Confidence: {conf:.2%}")
```

#### Táº¡o synthetic data

```python
from pipeline import generate_synthetic_scene
import cv2

# Táº¡o scene vá»›i 10 random objects
canvas, ground_truth = generate_synthetic_scene(
    mnist_dir='mnist_competition/train',
    shapes_dir='Shapes_Classifier/dataset/output',
    mnist_csv='mnist_competition/train_label.csv',
    num_objects=10,
    canvas_size=(800, 600),
    seed=42
)

# LÆ°u áº£nh
cv2.imwrite('my_test_scene.png', canvas)

# In ground truth
print("Ground truth labels:", [item[4] for item in ground_truth])
```

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
BTL_XLA/
â”œâ”€â”€ mnist_competition/              # MNIST dataset
â”‚   â”œâ”€â”€ train/                      # Training images
â”‚   â”œâ”€â”€ public_test/                # Test images
â”‚   â””â”€â”€ train_label.csv             # Labels
â”œâ”€â”€ Shapes_Classifier/              # Shapes dataset
â”‚   â””â”€â”€ dataset/output/             # Shape images
â”œâ”€â”€ train_unified_classifier.py     # Training script
â”œâ”€â”€ detect_objects.py               # Detection module
â”œâ”€â”€ pipeline.py                     # End-to-end pipeline
â”œâ”€â”€ preprocess_grid_image.py        # Preprocessing utilities
â”œâ”€â”€ unified_model_19classes_best.pth    # Trained model
â”œâ”€â”€ label_mapping.json              # Class mapping
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ CRAFT_SHAPES_GUIDE.md          # Detailed guide
â””â”€â”€ README.md                       # This file
```

## ğŸ¯ Class Mapping

| Class ID | Label | Category |
|----------|-------|----------|
| 0-9 | 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 | Digits |
| 10 | Circle | Shape |
| 11 | Heptagon | Shape |
| 12 | Hexagon | Shape |
| 13 | Nonagon | Shape |
| 14 | Octagon | Shape |
| 15 | Pentagon | Shape |
| 16 | Square | Shape |
| 17 | Star | Shape |
| 18 | Triangle | Shape |

## ğŸ“Š Hiá»‡u nÄƒng

### Classification Accuracy

| Dataset | Training | Validation |
|---------|----------|------------|
| MNIST Digits | 99.5% | 99.3% |
| Shapes | 99.0% | 98.5% |
| **Unified (19 classes)** | **99.3%** | **99.0%** |

### Inference Speed

| Component | Time (ms) |
|-----------|-----------|
| Detection | 50-150 |
| Classification | 5-10 per object |
| **Total** | **100-300** |

*Tested on RTX 4050*

## ğŸ”§ Advanced Usage

### Custom Detection Parameters

```python
from detect_objects import TraditionalDetector

detector = TraditionalDetector(
    min_area=200,
    max_area=30000,
    aspect_ratio_range=(0.2, 5.0)
)

bboxes = detector.detect(image)
```

### Synthetic Data Generation

```python
from pipeline import generate_synthetic_scene

canvas, ground_truth = generate_synthetic_scene(
    mnist_dir='mnist_competition/train',
    shapes_dir='Shapes_Classifier/dataset/output',
    mnist_csv='mnist_competition/train_label.csv',
    num_objects=5,
    canvas_size=(800, 600),
    seed=42
)
```

## ğŸ”„ HÆ°á»›ng dáº«n Push/Pull vá»›i GitHub (Sá»­ dá»¥ng Conda)

### Láº§n Ä‘áº§u push lÃªn GitHub

#### BÆ°á»›c 1: Táº¡o repository trÃªn GitHub

1. VÃ o [GitHub](https://github.com)
2. Click **New repository**
3. Äáº·t tÃªn: `BTL_XLA`
4. Chá»n **Public** hoáº·c **Private**
5. **KHÃ”NG** chá»n "Initialize with README"
6. Click **Create repository**

#### BÆ°á»›c 2: Setup Git local (náº¿u chÆ°a cÃ³)

```bash
# Kiá»ƒm tra Git Ä‘Ã£ cÃ i chÆ°a
git --version

# Náº¿u chÆ°a cÃ³, cÃ i Git
# Windows: Download tá»« https://git-scm.com/
# Linux: sudo apt install git
# macOS: brew install git

# Config thÃ´ng tin (chá»‰ cáº§n 1 láº§n)
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
```

#### BÆ°á»›c 3: Khá»Ÿi táº¡o Git repository

```bash
# Activate conda environment
conda activate btl_xla

# Di chuyá»ƒn vÃ o thÆ° má»¥c project
cd D:\BTL_XLA

# Khá»Ÿi táº¡o Git repository
git init

# Kiá»ƒm tra status
git status
```

#### BÆ°á»›c 4: Add files vÃ  commit

```bash
# Add táº¥t cáº£ files (theo .gitignore)
git add .

# Kiá»ƒm tra nhá»¯ng gÃ¬ sáº½ commit
git status

# Commit láº§n Ä‘áº§u
git commit -m "Initial commit: Unified Digits & Shapes Recognition System"
```

#### BÆ°á»›c 5: Káº¿t ná»‘i vá»›i GitHub vÃ  push

```bash
# ThÃªm remote repository (thay YOUR_USERNAME báº±ng username GitHub cá»§a báº¡n)
git remote add origin https://github.com/YOUR_USERNAME/BTL_XLA.git

# Kiá»ƒm tra remote
git remote -v

# Push lÃªn GitHub (branch main)
git branch -M main
git push -u origin main
```

**LÆ°u Ã½ vá» viá»‡c push:**
- Theo `.gitignore`, nhá»¯ng thá»© SAU sáº½ Ä‘Æ°á»£c push:
  - âœ… `craft_repo/` (full folder)
  - âœ… `mnist_competition.zip` (file nÃ©n)
  - âœ… `mnist_competition/*.csv` (cÃ¡c file CSV)
  - âœ… `Shapes_Classifier/` (trá»« folder `dataset/`)
  - âœ… `weights/craft_mlt_25k.pth`
  - âœ… `unified_model_19classes_best.pth`
  - âœ… Táº¥t cáº£ `.py`, `.ipynb`, `.md`, `requirements.txt`
  - âœ… `Sample.png`, `label_mapping.json`

- Nhá»¯ng thá»© SAU sáº½ KHÃ”NG push (Ä‘Ã£ bá»‹ ignore):
  - âŒ `mnist_competition/train/` (60,000 áº£nh)
  - âŒ `mnist_competition/public_test/` (10,000 áº£nh)
  - âŒ `Shapes_Classifier/dataset/` (90,000 áº£nh)
  - âŒ `__pycache__/`, `.ipynb_checkpoints/`
  - âŒ `*_result.png`, `*_result.json`
  - âŒ `Test_*.png`, `Test_*.jpg`

### Khi muá»‘n update code (push thay Ä‘á»•i má»›i)

```bash
# Activate environment
conda activate btl_xla

# Kiá»ƒm tra thay Ä‘á»•i
git status

# Add files Ä‘Ã£ thay Ä‘á»•i
git add .

# Commit vá»›i message mÃ´ táº£
git commit -m "Update: Improved detection accuracy"

# Push lÃªn GitHub
git push origin main
```

### Khi muá»‘n táº£i code má»›i (pull tá»« GitHub)

```bash
# Pull code má»›i nháº¥t
git pull origin main

# Náº¿u bá»‹ conflict, Git sáº½ bÃ¡o - cáº§n resolve manually
```

### Clone project tá»« GitHub (cho mÃ¡y khÃ¡c)

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/BTL_XLA.git
cd BTL_XLA

# Setup conda environment
conda create -n btl_xla python=3.10 -y
conda activate btl_xla

# CÃ i Ä‘áº·t dependencies
conda install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia -y
pip install -r requirements.txt

# Giáº£i nÃ©n datasets
unzip mnist_competition.zip
cd Shapes_Classifier
unzip dataset.zip
cd ..

# Cháº¡y pipeline
python pipeline.py --generate --num-objects 5
```

### Git Commands thÆ°á»ng dÃ¹ng

```bash
# Xem lá»‹ch sá»­ commit
git log --oneline

# Xem thay Ä‘á»•i chÆ°a commit
git diff

# Há»§y thay Ä‘á»•i chÆ°a add
git restore filename.py

# Táº¡o branch má»›i
git checkout -b feature/new-feature

# Chuyá»ƒn branch
git checkout main

# Merge branch
git merge feature/new-feature

# Xem táº¥t cáº£ branches
git branch -a
```

## ğŸ› Troubleshooting

### Lá»—i: Model khÃ´ng load Ä‘Æ°á»£c

```bash
# Kiá»ƒm tra PyTorch version
python -c "import torch; print(torch.__version__)"

# Kiá»ƒm tra CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

### Lá»—i: Out of memory

- Giáº£m batch size: `--batch-size 32`
- Sá»­ dá»¥ng CPU: `--device cpu`
- Giáº£m resolution cá»§a áº£nh input

### Detection rate tháº¥p

- Äiá»u chá»‰nh threshold: `min_area=100`
- Thá»­ detector khÃ¡c: `--detector hybrid`

## ğŸ“„ TÃ i liá»‡u tham kháº£o

- [CRAFT Paper](https://arxiv.org/abs/1904.01941) - Character Region Awareness For Text detection
- [EfficientNet Paper](https://arxiv.org/abs/1905.11946) - Efficient Convolutional Neural Networks
- [CRAFT GitHub](https://github.com/clovaai/CRAFT-pytorch) - Official CRAFT implementation
- [Detailed Guide](CRAFT_SHAPES_GUIDE.md) - HÆ°á»›ng dáº«n chi tiáº¿t

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh! Vui lÃ²ng:

1. Fork repository
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Má»Ÿ Pull Request

## ğŸ“ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch giÃ¡o dá»¥c.

## ğŸ‘¥ TÃ¡c giáº£

- Äá»“ Ã¡n mÃ´n Xá»­ lÃ½ áº£nh (Image Processing)
- TrÆ°á»ng Äáº¡i há»c...

## ğŸ™ Acknowledgments

- MNIST Dataset
- Shapes Dataset
- CRAFT-pytorch
- EfficientNet

---

**â­ Náº¿u project há»¯u Ã­ch, Ä‘á»«ng quÃªn cho má»™t star nhÃ©!**

## ğŸ“ LiÃªn há»‡

Náº¿u cÃ³ cÃ¢u há»i hoáº·c váº¥n Ä‘á», vui lÃ²ng táº¡o [Issue](../../issues) trÃªn GitHub.

