# ğŸ¯ Unified Digits & Shapes Recognition System

Há»‡ thá»‘ng nháº­n diá»‡n chá»¯ sá»‘ viáº¿t tay vÃ  hÃ¬nh há»c trong áº£nh sá»­ dá»¥ng Deep Learning vá»›i kiáº¿n trÃºc Detection + Classification.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“– MÃ´ táº£

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng hoÃ n chá»‰nh Ä‘á»ƒ nháº­n diá»‡n vÃ  phÃ¢n loáº¡i:
- **10 chá»¯ sá»‘**: 0-9 (tá»« MNIST dataset)
- **9 hÃ¬nh há»c**: Circle, Triangle, Square, Pentagon, Hexagon, Heptagon, Octagon, Nonagon, Star

### Pipeline

```
Input Image â†’ Detection (Traditional CV/CRAFT) â†’ Classification (EfficientNet-B0) â†’ Output (Annotated Image + JSON)
```

### Äáº·c Ä‘iá»ƒm ná»•i báº­t

- âœ… **19 classes**: Digits (0-9) + Shapes (9 loáº¡i)
- âœ… **Äá»™ chÃ­nh xÃ¡c cao**: ~99% validation accuracy
- âœ… **Inference nhanh**: ~100-300ms/áº£nh
- âœ… **Linh hoáº¡t**: Há»— trá»£ nhiá»u phÆ°Æ¡ng phÃ¡p detection
- âœ… **Dá»… sá»­ dá»¥ng**: API Ä‘Æ¡n giáº£n vÃ  rÃµ rÃ ng

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng

- Python 3.8+
- CUDA (optional, cho GPU acceleration)
- RAM: 8GB+ (16GB recommended)

### CÃ i Ä‘áº·t dependencies

```bash
# Clone repository
git clone <your-repo-url>
cd BTL_XLA

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
pip install -r requirements.txt
```

### Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº£m báº£o cáº¥u trÃºc thÆ° má»¥c nhÆ° sau:

```
BTL_XLA/
â”œâ”€â”€ mnist_competition/
â”‚   â”œâ”€â”€ train/              # 60,000 MNIST images
â”‚   â””â”€â”€ train_label.csv
â””â”€â”€ Shapes_Classifier/
    â””â”€â”€ dataset/output/     # 90,000 shape images
```

## ğŸ“š HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. Training Classifier

Train mÃ´ hÃ¬nh EfficientNet-B0 trÃªn 19 classes:

```bash
python train_unified_classifier.py --epochs 10 --batch-size 64
```

**Tham sá»‘:**
- `--epochs`: Sá»‘ epoch (máº·c Ä‘á»‹nh: 10)
- `--batch-size`: Batch size (máº·c Ä‘á»‹nh: 64)
- `--lr`: Learning rate (máº·c Ä‘á»‹nh: 1e-4)

**Output:**
- `unified_model_19classes_best.pth`: Model Ä‘Ã£ train
- `label_mapping.json`: Ãnh xáº¡ class labels

### 2. Inference trÃªn áº£nh

#### Xá»­ lÃ½ áº£nh cÃ³ sáºµn

```bash
python pipeline.py --image your_image.png --output result.png
```

#### Táº¡o áº£nh test synthetic

```bash
python pipeline.py --generate --num-objects 7
```

**Output:**
- `result.png`: áº¢nh Ä‘Æ°á»£c annotate vá»›i bounding boxes
- `result.json`: Káº¿t quáº£ detection á»Ÿ Ä‘á»‹nh dáº¡ng JSON

### 3. Sá»­ dá»¥ng nhÆ° má»™t module

```python
from pipeline import UnifiedPipeline

# Khá»Ÿi táº¡o pipeline
pipeline = UnifiedPipeline(
    model_path='unified_model_19classes_best.pth',
    label_mapping_path='label_mapping.json',
    device='cuda'  # hoáº·c 'cpu'
)

# Xá»­ lÃ½ áº£nh
results = pipeline.process_file('test_image.png')

# Káº¿t quáº£
print(f"Detected {len(results['labels'])} objects")
for label, conf in zip(results['labels'], results['confidences']):
    print(f"Class: {label}, Confidence: {conf:.2%}")
```

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
BTL_XLA/
â”œâ”€â”€ mnist_competition/              # MNIST dataset
â”‚   â”œâ”€â”€ train/                      # Training images
â”‚   â”œâ”€â”€ public_test/                # Test images
â”‚   â””â”€â”€ train_label.csv             # Labels
â”œâ”€â”€ Shapes_Classifier/              # Shapes dataset
â”‚   â””â”€â”€ dataset/output/             # Shape images
â”œâ”€â”€ train_unified_classifier.py     # Training script
â”œâ”€â”€ detect_objects.py               # Detection module
â”œâ”€â”€ pipeline.py                     # End-to-end pipeline
â”œâ”€â”€ preprocess_grid_image.py        # Preprocessing utilities
â”œâ”€â”€ unified_model_19classes_best.pth    # Trained model
â”œâ”€â”€ label_mapping.json              # Class mapping
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ CRAFT_SHAPES_GUIDE.md          # Detailed guide
â””â”€â”€ README.md                       # This file
```

## ğŸ¯ Class Mapping

| Class ID | Label | Category |
|----------|-------|----------|
| 0-9 | 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 | Digits |
| 10 | Circle | Shape |
| 11 | Heptagon | Shape |
| 12 | Hexagon | Shape |
| 13 | Nonagon | Shape |
| 14 | Octagon | Shape |
| 15 | Pentagon | Shape |
| 16 | Square | Shape |
| 17 | Star | Shape |
| 18 | Triangle | Shape |

## ğŸ“Š Hiá»‡u nÄƒng

### Classification Accuracy

| Dataset | Training | Validation |
|---------|----------|------------|
| MNIST Digits | 99.5% | 99.3% |
| Shapes | 99.0% | 98.5% |
| **Unified (19 classes)** | **99.3%** | **99.0%** |

### Inference Speed

| Component | Time (ms) |
|-----------|-----------|
| Detection | 50-150 |
| Classification | 5-10 per object |
| **Total** | **100-300** |

*Tested on RTX 4050*

## ğŸ”§ Advanced Usage

### Custom Detection Parameters

```python
from detect_objects import TraditionalDetector

detector = TraditionalDetector(
    min_area=200,
    max_area=30000,
    aspect_ratio_range=(0.2, 5.0)
)

bboxes = detector.detect(image)
```

### Synthetic Data Generation

```python
from pipeline import generate_synthetic_scene

canvas, ground_truth = generate_synthetic_scene(
    mnist_dir='mnist_competition/train',
    shapes_dir='Shapes_Classifier/dataset/output',
    mnist_csv='mnist_competition/train_label.csv',
    num_objects=5,
    canvas_size=(800, 600),
    seed=42
)
```

## ğŸ› Troubleshooting

### Lá»—i: Model khÃ´ng load Ä‘Æ°á»£c

```bash
# Kiá»ƒm tra PyTorch version
python -c "import torch; print(torch.__version__)"

# Kiá»ƒm tra CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

### Lá»—i: Out of memory

- Giáº£m batch size: `--batch-size 32`
- Sá»­ dá»¥ng CPU: `--device cpu`
- Giáº£m resolution cá»§a áº£nh input

### Detection rate tháº¥p

- Äiá»u chá»‰nh threshold: `min_area=100`
- Thá»­ detector khÃ¡c: `--detector hybrid`

## ğŸ“„ TÃ i liá»‡u tham kháº£o

- [CRAFT Paper](https://arxiv.org/abs/1904.01941) - Character Region Awareness For Text detection
- [EfficientNet Paper](https://arxiv.org/abs/1905.11946) - Efficient Convolutional Neural Networks
- [CRAFT GitHub](https://github.com/clovaai/CRAFT-pytorch) - Official CRAFT implementation
- [Detailed Guide](CRAFT_SHAPES_GUIDE.md) - HÆ°á»›ng dáº«n chi tiáº¿t

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh! Vui lÃ²ng:

1. Fork repository
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Má»Ÿ Pull Request

## ğŸ“ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch giÃ¡o dá»¥c.

## ğŸ‘¥ TÃ¡c giáº£

- Äá»“ Ã¡n mÃ´n Xá»­ lÃ½ áº£nh (Image Processing)
- TrÆ°á»ng Äáº¡i há»c...

## ğŸ™ Acknowledgments

- MNIST Dataset
- Shapes Dataset
- CRAFT-pytorch
- EfficientNet

---

**â­ Náº¿u project há»¯u Ã­ch, Ä‘á»«ng quÃªn cho má»™t star nhÃ©!**

## ğŸ“ LiÃªn há»‡

Náº¿u cÃ³ cÃ¢u há»i hoáº·c váº¥n Ä‘á», vui lÃ²ng táº¡o [Issue](../../issues) trÃªn GitHub.

